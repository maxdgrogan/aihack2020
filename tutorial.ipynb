{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys \n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "sys.path.append(\"./\")\n",
    "from prediction.api import *\n",
    "from prediction.data_wrapper import get_loaders\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.data = './data/processed/processed_cleaned_df.csv'\n",
    "args.input_size = [33]\n",
    "args.hidden_size = 300\n",
    "args.number_of_layers = 10\n",
    "args.output_size = [1]\n",
    "args.test_portion = 0.2 \n",
    "args.train_window = 12\n",
    "args.batch_size = 64\n",
    "args.learning_rate = 0.001\n",
    "args.weight_decay = 0.0001\n",
    "args.gpu = 0 \n",
    "args.epochs = 100\n",
    "args.log_freq = 30\n",
    "args.debug = False\n",
    "args.seed = 1\n",
    "args.samples = 20\n",
    "args.dropout = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "GPs  month      07    0304  050103  131002     2101   010305       01  \\\n0  A81001      1  7271.0  4071.0  1476.0   185.0  4964.00  13032.0  69503.0   \n1  A81001      2  8527.0  4071.0  1427.0   191.0  3841.00  12740.0  78753.0   \n2  A81001      3  6402.0  3928.0  1278.0   198.0  4188.25  11574.0  65473.0   \n3  A81001      4  7295.0  4836.0  1537.0   231.0  4535.50  13019.0  74436.0   \n4  A81001      5  6671.0  5153.0  1436.0   280.0  4882.75  11824.0  65084.0   \n\n       05  ...  030401       13           12     0106     1302       10  \\\n0  9767.0  ...  4310.0  59472.0   886.000000  19797.0  49930.0  15657.0   \n1  9767.0  ...  4064.0  59472.0   994.666667  24304.0  49930.0  12903.0   \n2  9767.0  ...  3928.0  59472.0  1103.333333  20416.0  44955.0  13236.0   \n3  9767.0  ...  4836.0  58722.0  1212.000000  24713.0  45005.0  14082.0   \n4  9767.0  ...  5152.0  57972.0   817.000000  20309.0  42955.0  12972.0   \n\n    130201  050108    0603   010604  \n0  41880.0   998.0  4034.0  10939.0  \n1  48830.0  1568.0  4310.0  11102.0  \n2  44555.0  1970.0  2456.0  11762.0  \n3  44155.0  1532.0  2551.0  15466.0  \n4  42365.0  1034.0  2239.0  10967.0  \n\n[5 rows x 34 columns]\n"
    }
   ],
   "source": [
    "df = pd.read_csv(args.data).iloc[:,1:]\n",
    "label_index = df.columns.get_loc('0301')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.to_numpy()\n",
    "gps = data[:,0]\n",
    "features = data[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(398518, 33) (398518,)\n"
    }
   ],
   "source": [
    "print(features.shape, gps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size = len(features)\n",
    "train_size = int((1-args.test_portion) * total_size)\n",
    "\n",
    "train_data = features[:train_size]\n",
    "test_data = features[train_size:]\n",
    "\n",
    "train_gps = gps[:train_size]\n",
    "test_gps = gps[train_size:]\n",
    "\n",
    "train_unique_gps = np.unique(train_gps)\n",
    "test_unique_gps = np.unique(test_gps)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "train_data_normalized = scaler.fit_transform(train_data)\n",
    "test_data_normalized = scaler.transform(test_data)\n",
    "\n",
    "train_data_normalized = torch.FloatTensor(train_data_normalized)\n",
    "test_data_normalized = torch.FloatTensor(test_data_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "100%|██████████| 5497/5497 [00:36<00:00, 149.47it/s]\n100%|██████████| 1375/1375 [00:03<00:00, 381.20it/s]\n"
    }
   ],
   "source": [
    "def create_inout_sequences(input_data,_gps,_unique_gps,_label_index, tw):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i in tqdm(range(len(_unique_gps))):\n",
    "        for j in range(len(_gps[_gps == _unique_gps[i]]) - tw):\n",
    "            seq = input_data[j:j+tw]\n",
    "            label = input_data[j+tw:j+tw+1,_label_index]\n",
    "            seq = np.array(seq, dtype=np.float32)\n",
    "            label = np.array(label, dtype = np.float32)\n",
    "            X.append(torch.from_numpy(seq).float())\n",
    "            Y.append(torch.from_numpy(label).float())\n",
    "\n",
    "    return X, Y\n",
    "X_train, Y_train = create_inout_sequences(train_data_normalized, train_gps, train_unique_gps, label_index, args.train_window)\n",
    "X_test, Y_test = create_inout_sequences(test_data_normalized, test_gps, test_unique_gps, label_index, args.train_window)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "torch.Size([252850, 12, 33]) torch.Size([252850, 1])\ntorch.Size([63204, 12, 33]) torch.Size([63204, 1])\n"
    }
   ],
   "source": [
    "X_train = torch.stack(X_train)\n",
    "X_test = torch.stack(X_test)\n",
    "Y_train = torch.stack(Y_train)\n",
    "Y_test = torch.stack(Y_test)\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(X, Y):\n",
    "    dataset = torch.utils.data.TensorDataset(X,Y)\n",
    "    return torch.utils.data.DataLoader(dataset,batch_size = args.batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_loaders(X_train, Y_train)\n",
    "test_loader = get_loaders(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, scaler = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.6.4 64-bit ('venv': virtualenv)",
   "language": "python",
   "name": "python36464bitvenvvirtualenva637c86ce3cd46188993e29d564fd96c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}