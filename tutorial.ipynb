{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys \n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "sys.path.append(\"./\")\n",
    "from prediction.api import *\n",
    "from prediction.data_wrapper import get_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.data = './data/processed/processed_cleaned_df.csv'\n",
    "args.input_size = [33]\n",
    "args.hidden_size = 300\n",
    "args.number_of_layers = 10\n",
    "args.output_size = [1]\n",
    "args.test_portion = 0.2 \n",
    "args.train_window = 12\n",
    "args.batch_size = 64\n",
    "args.learning_rate = 0.001\n",
    "args.weight_decay = 0.0001\n",
    "args.gpu = -1 \n",
    "args.epochs = 100\n",
    "args.log_freq = 30\n",
    "args.debug = False\n",
    "args.seed = 1\n",
    "args.samples = 20\n",
    "args.dropout = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      GPs  month      07    0304  050103  131002     2101   010305       01  \\\n",
      "0  A81001      1  7271.0  4071.0  1476.0   185.0  4964.00  13032.0  69503.0   \n",
      "1  A81001      2  8527.0  4071.0  1427.0   191.0  3841.00  12740.0  78753.0   \n",
      "2  A81001      3  6402.0  3928.0  1278.0   198.0  4188.25  11574.0  65473.0   \n",
      "3  A81001      4  7295.0  4836.0  1537.0   231.0  4535.50  13019.0  74436.0   \n",
      "4  A81001      5  6671.0  5153.0  1436.0   280.0  4882.75  11824.0  65084.0   \n",
      "\n",
      "       05  ...  030401       13           12     0106     1302       10  \\\n",
      "0  9767.0  ...  4310.0  59472.0   886.000000  19797.0  49930.0  15657.0   \n",
      "1  9767.0  ...  4064.0  59472.0   994.666667  24304.0  49930.0  12903.0   \n",
      "2  9767.0  ...  3928.0  59472.0  1103.333333  20416.0  44955.0  13236.0   \n",
      "3  9767.0  ...  4836.0  58722.0  1212.000000  24713.0  45005.0  14082.0   \n",
      "4  9767.0  ...  5152.0  57972.0   817.000000  20309.0  42955.0  12972.0   \n",
      "\n",
      "    130201  050108    0603   010604  \n",
      "0  41880.0   998.0  4034.0  10939.0  \n",
      "1  48830.0  1568.0  4310.0  11102.0  \n",
      "2  44555.0  1970.0  2456.0  11762.0  \n",
      "3  44155.0  1532.0  2551.0  15466.0  \n",
      "4  42365.0  1034.0  2239.0  10967.0  \n",
      "\n",
      "[5 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(args.data).iloc[:,1:]\n",
    "label_index = df.columns.get_loc('0407')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.to_numpy()\n",
    "gps = data[:,0]\n",
    "features = data[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398518, 33) (398518,)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape, gps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size = len(features)\n",
    "train_size = int((1-args.test_portion) * total_size)\n",
    "\n",
    "train_data = features[:train_size]\n",
    "test_data = features[train_size:]\n",
    "\n",
    "train_gps = gps[:train_size]\n",
    "test_gps = gps[train_size:]\n",
    "\n",
    "train_unique_gps = np.unique(train_gps)\n",
    "test_unique_gps = np.unique(test_gps)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "train_data_normalized = scaler.fit_transform(train_data)\n",
    "test_data_normalized = scaler.transform(test_data)\n",
    "\n",
    "train_data_normalized = torch.FloatTensor(train_data_normalized)\n",
    "test_data_normalized = torch.FloatTensor(test_data_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5497/5497 [00:32<00:00, 166.77it/s]\n",
      "100%|██████████| 1375/1375 [00:03<00:00, 409.55it/s]\n"
     ]
    }
   ],
   "source": [
    "def create_inout_sequences(input_data,_gps,_unique_gps,_label_index, tw):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i in tqdm(range(len(_unique_gps))):\n",
    "        for j in range(len(_gps[_gps == _unique_gps[i]]) - tw):\n",
    "            seq = input_data[j:j+tw]\n",
    "            label = input_data[j+tw:j+tw+1,_label_index]\n",
    "            seq = np.array(seq, dtype=np.float32)\n",
    "            label = np.array(label, dtype = np.float32)\n",
    "            X.append(torch.from_numpy(seq).float())\n",
    "            Y.append(torch.from_numpy(label).float())\n",
    "\n",
    "    return X, Y\n",
    "X_train, Y_train = create_inout_sequences(train_data_normalized, train_gps, train_unique_gps, label_index, args.train_window)\n",
    "X_test, Y_test = create_inout_sequences(test_data_normalized, test_gps, test_unique_gps, label_index, args.train_window)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([252850, 12, 33]) torch.Size([252850, 1])\n",
      "torch.Size([63204, 12, 33]) torch.Size([63204, 1])\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.stack(X_train)\n",
    "X_test = torch.stack(X_test)\n",
    "Y_train = torch.stack(Y_train)\n",
    "Y_test = torch.stack(Y_test)\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(X, Y):\n",
    "    dataset = torch.utils.data.TensorDataset(X,Y)\n",
    "    return torch.utils.data.DataLoader(dataset,batch_size = args.batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_loaders(X_train, Y_train)\n",
    "test_loader = get_loaders(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8438],\n",
      "        [-0.8475],\n",
      "        [-0.8512],\n",
      "        ...,\n",
      "        [-0.8934],\n",
      "        [-0.8932],\n",
      "        [-0.8930]])\n"
     ]
    }
   ],
   "source": [
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/01 01:38:54 AM | # START #\n",
      "03/01 01:38:54 AM | Args = Namespace(batch_size=64, data='./data/processed/processed_cleaned_df.csv', debug=False, dropout=0.3, epochs=100, f='/Users/martinferianc/Library/Jupyter/runtime/kernel-6d3ed8b8-10e2-490a-8f13-9cec97ac2ff8.json', gpu=-1, hidden_size=300, input_size=[33], layers=8, learning_rate=0.001, log_freq=30, model_path='./model/drugs-EXP-20200301-013812/drugs-EXP-20200301-013812.model', num_of_layers=1, number_of_layers=10, output_size=[1], samples=20, save='./model/drugs-EXP-20200301-013812', seed=1, test_portion=0.2, train_window=12, weight_decay=0.0001)\n",
      "INFO:net:Args = Namespace(batch_size=64, data='./data/processed/processed_cleaned_df.csv', debug=False, dropout=0.3, epochs=100, f='/Users/martinferianc/Library/Jupyter/runtime/kernel-6d3ed8b8-10e2-490a-8f13-9cec97ac2ff8.json', gpu=-1, hidden_size=300, input_size=[33], layers=8, learning_rate=0.001, log_freq=30, model_path='./model/drugs-EXP-20200301-013812/drugs-EXP-20200301-013812.model', num_of_layers=1, number_of_layers=10, output_size=[1], samples=20, save='./model/drugs-EXP-20200301-013812', seed=1, test_portion=0.2, train_window=12, weight_decay=0.0001)\n",
      "03/01 01:38:54 AM | ## Creating model and criterion ##\n",
      "INFO:net:## Creating model and criterion ##\n",
      "/Users/martinferianc/Desktop/aihack2020/venv/lib/python3.6/site-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "03/01 01:38:54 AM | ## Getting and possibly pre-processing data ##\n",
      "INFO:net:## Getting and possibly pre-processing data ##\n",
      "03/01 01:38:54 AM | ## Beginning training ##\n",
      "INFO:net:## Beginning training ##\n",
      "03/01 01:38:54 AM | ### Start to train weights for 100 epochs #### \n",
      "INFO:net:### Start to train weights for 100 epochs #### \n",
      "03/01 01:38:54 AM | #### Training weights for epoch 0 #### \n",
      "INFO:net:#### Training weights for epoch 0 #### \n",
      "03/01 01:38:55 AM | #### Train: [  1/100] Step 030/3950 MSE 0.0508+-0.00000\n",
      "INFO:net:#### Train: [  1/100] Step 030/3950 MSE 0.0508+-0.00000\n",
      "03/01 01:38:56 AM | #### Train: [  1/100] Step 060/3950 MSE 0.0263+-0.00000\n",
      "INFO:net:#### Train: [  1/100] Step 060/3950 MSE 0.0263+-0.00000\n",
      "03/01 01:38:57 AM | #### Train: [  1/100] Step 090/3950 MSE 0.0177+-0.00000\n",
      "INFO:net:#### Train: [  1/100] Step 090/3950 MSE 0.0177+-0.00000\n",
      "03/01 01:38:58 AM | #### Train: [  1/100] Step 120/3950 MSE 0.0134+-0.00000\n",
      "INFO:net:#### Train: [  1/100] Step 120/3950 MSE 0.0134+-0.00000\n",
      "03/01 01:38:59 AM | #### Train: [  1/100] Step 150/3950 MSE 0.0108+-0.00000\n",
      "INFO:net:#### Train: [  1/100] Step 150/3950 MSE 0.0108+-0.00000\n",
      "03/01 01:39:01 AM | #### Train: [  1/100] Step 180/3950 MSE 0.0091+-0.00000\n",
      "INFO:net:#### Train: [  1/100] Step 180/3950 MSE 0.0091+-0.00000\n",
      "03/01 01:39:02 AM | #### Train: [  1/100] Step 210/3950 MSE 0.0078+-0.00000\n",
      "INFO:net:#### Train: [  1/100] Step 210/3950 MSE 0.0078+-0.00000\n",
      "03/01 01:39:03 AM | #### Train: [  1/100] Step 240/3950 MSE 0.0069+-0.00000\n",
      "INFO:net:#### Train: [  1/100] Step 240/3950 MSE 0.0069+-0.00000\n",
      "03/01 01:39:04 AM | #### Train: [  1/100] Step 270/3950 MSE 0.0061+-0.00000\n",
      "INFO:net:#### Train: [  1/100] Step 270/3950 MSE 0.0061+-0.00000\n",
      "03/01 01:39:06 AM | #### Train: [  1/100] Step 300/3950 MSE 0.0056+-0.00000\n",
      "INFO:net:#### Train: [  1/100] Step 300/3950 MSE 0.0056+-0.00000\n",
      "03/01 01:39:07 AM | #### Train: [  1/100] Step 330/3950 MSE 0.0051+-0.00000\n",
      "INFO:net:#### Train: [  1/100] Step 330/3950 MSE 0.0051+-0.00000\n",
      "03/01 01:39:08 AM | #### Train: [  1/100] Step 360/3950 MSE 0.0047+-0.00000\n",
      "INFO:net:#### Train: [  1/100] Step 360/3950 MSE 0.0047+-0.00000\n",
      "03/01 01:39:09 AM | #### Train: [  1/100] Step 390/3950 MSE 0.0043+-0.00000\n",
      "INFO:net:#### Train: [  1/100] Step 390/3950 MSE 0.0043+-0.00000\n",
      "03/01 01:39:10 AM | #### Train: [  1/100] Step 420/3950 MSE 0.0040+-0.00000\n",
      "INFO:net:#### Train: [  1/100] Step 420/3950 MSE 0.0040+-0.00000\n",
      "03/01 01:39:12 AM | #### Train: [  1/100] Step 450/3950 MSE 0.0038+-0.00000\n",
      "INFO:net:#### Train: [  1/100] Step 450/3950 MSE 0.0038+-0.00000\n",
      "03/01 01:39:13 AM | #### Train: [  1/100] Step 480/3950 MSE 0.0036+-0.00000\n",
      "INFO:net:#### Train: [  1/100] Step 480/3950 MSE 0.0036+-0.00000\n",
      "03/01 01:39:14 AM | #### Train: [  1/100] Step 510/3950 MSE 0.0034+-0.00000\n",
      "INFO:net:#### Train: [  1/100] Step 510/3950 MSE 0.0034+-0.00000\n",
      "03/01 01:39:15 AM | #### Train: [  1/100] Step 540/3950 MSE 0.0032+-0.00000\n",
      "INFO:net:#### Train: [  1/100] Step 540/3950 MSE 0.0032+-0.00000\n"
     ]
    }
   ],
   "source": [
    "model = get_model(train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.6.4 64-bit ('venv': virtualenv)",
   "language": "python",
   "name": "python36464bitvenvvirtualenva637c86ce3cd46188993e29d564fd96c"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
