{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys \n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "sys.path.append(\"./\")\n",
    "from prediction.api import *\n",
    "from prediction.data_wrapper import get_loaders\n",
    "from pickle import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.data = './data/processed/processed_cleaned_df.csv'\n",
    "args.input_size = [33]\n",
    "args.hidden_size = 300\n",
    "args.number_of_layers = 10\n",
    "args.output_size = [1]\n",
    "args.test_portion = 0.2 \n",
    "args.train_window = 12\n",
    "args.batch_size = 64\n",
    "args.learning_rate = 0.001\n",
    "args.weight_decay = 0.0001\n",
    "args.gpu = 0 \n",
    "args.epochs = 100\n",
    "args.log_freq = 30\n",
    "args.debug = False\n",
    "args.seed = 1\n",
    "args.samples = 20\n",
    "args.dropout = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "GPs  month      07    0304  050103  131002     2101   010305       01  \\\n0  A81001      1  7271.0  4071.0  1476.0   185.0  4964.00  13032.0  69503.0   \n1  A81001      2  8527.0  4071.0  1427.0   191.0  3841.00  12740.0  78753.0   \n2  A81001      3  6402.0  3928.0  1278.0   198.0  4188.25  11574.0  65473.0   \n3  A81001      4  7295.0  4836.0  1537.0   231.0  4535.50  13019.0  74436.0   \n4  A81001      5  6671.0  5153.0  1436.0   280.0  4882.75  11824.0  65084.0   \n\n       05  ...  030401       13           12     0106     1302       10  \\\n0  9767.0  ...  4310.0  59472.0   886.000000  19797.0  49930.0  15657.0   \n1  9767.0  ...  4064.0  59472.0   994.666667  24304.0  49930.0  12903.0   \n2  9767.0  ...  3928.0  59472.0  1103.333333  20416.0  44955.0  13236.0   \n3  9767.0  ...  4836.0  58722.0  1212.000000  24713.0  45005.0  14082.0   \n4  9767.0  ...  5152.0  57972.0   817.000000  20309.0  42955.0  12972.0   \n\n    130201  050108    0603   010604  \n0  41880.0   998.0  4034.0  10939.0  \n1  48830.0  1568.0  4310.0  11102.0  \n2  44555.0  1970.0  2456.0  11762.0  \n3  44155.0  1532.0  2551.0  15466.0  \n4  42365.0  1034.0  2239.0  10967.0  \n\n[5 rows x 34 columns]\n"
    }
   ],
   "source": [
    "df = pd.read_csv(args.data).iloc[:,1:]\n",
    "label_index = df.columns.get_loc('0301')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.to_numpy()\n",
    "gps = data[:,0]\n",
    "features = data[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(398518, 33) (398518,)\n"
    }
   ],
   "source": [
    "print(features.shape, gps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size = len(features)\n",
    "train_size = int((1-args.test_portion) * total_size)\n",
    "\n",
    "train_data = features[:train_size]\n",
    "test_data = features[train_size:]\n",
    "\n",
    "train_gps = gps[:train_size]\n",
    "test_gps = gps[train_size:]\n",
    "\n",
    "train_unique_gps = np.unique(train_gps)\n",
    "test_unique_gps = np.unique(test_gps)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "train_data_normalized = scaler.fit_transform(train_data)\n",
    "test_data_normalized = scaler.transform(test_data)\n",
    "\n",
    "train_data_normalized = torch.FloatTensor(train_data_normalized)\n",
    "test_data_normalized = torch.FloatTensor(test_data_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "100%|██████████| 5497/5497 [00:29<00:00, 185.10it/s]\n100%|██████████| 1375/1375 [00:02<00:00, 498.84it/s]\n"
    }
   ],
   "source": [
    "def create_inout_sequences(input_data,_gps,_unique_gps,_label_index, tw):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i in tqdm(range(len(_unique_gps))):\n",
    "        for j in range(len(_gps[_gps == _unique_gps[i]]) - tw):\n",
    "            seq = input_data[j:j+tw]\n",
    "            label = input_data[j+tw:j+tw+1,_label_index]\n",
    "            seq = np.array(seq, dtype=np.float32)\n",
    "            label = np.array(label, dtype = np.float32)\n",
    "            X.append(torch.from_numpy(seq).float())\n",
    "            Y.append(torch.from_numpy(label).float())\n",
    "\n",
    "    return X, Y\n",
    "X_train, Y_train = create_inout_sequences(train_data_normalized, train_gps, train_unique_gps, label_index, args.train_window)\n",
    "X_test, Y_test = create_inout_sequences(test_data_normalized, test_gps, test_unique_gps, label_index, args.train_window)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "torch.Size([252850, 12, 33]) torch.Size([252850, 1])\ntorch.Size([63204, 12, 33]) torch.Size([63204, 1])\n"
    }
   ],
   "source": [
    "X_train = torch.stack(X_train)\n",
    "X_test = torch.stack(X_test)\n",
    "Y_train = torch.stack(Y_train)\n",
    "Y_test = torch.stack(Y_test)\n",
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loaders(X, Y):\n",
    "    dataset = torch.utils.data.TensorDataset(X,Y)\n",
    "    return torch.utils.data.DataLoader(dataset,batch_size = args.batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_loaders(X_train, Y_train)\n",
    "test_loader = get_loaders(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "8:54:22 PM | #### Train: [  3/100] Step 480/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 480/3950 MSE 0.0005+-0.00000\n02/29 08:54:22 PM | #### Train: [  3/100] Step 510/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 510/3950 MSE 0.0005+-0.00000\n02/29 08:54:22 PM | #### Train: [  3/100] Step 540/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 540/3950 MSE 0.0005+-0.00000\n02/29 08:54:22 PM | #### Train: [  3/100] Step 570/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 570/3950 MSE 0.0005+-0.00000\n02/29 08:54:22 PM | #### Train: [  3/100] Step 600/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 600/3950 MSE 0.0005+-0.00000\n02/29 08:54:22 PM | #### Train: [  3/100] Step 630/3950 MSE 0.0006+-0.00000\nINFO:net:#### Train: [  3/100] Step 630/3950 MSE 0.0006+-0.00000\n02/29 08:54:22 PM | #### Train: [  3/100] Step 660/3950 MSE 0.0006+-0.00000\nINFO:net:#### Train: [  3/100] Step 660/3950 MSE 0.0006+-0.00000\n02/29 08:54:22 PM | #### Train: [  3/100] Step 690/3950 MSE 0.0006+-0.00000\nINFO:net:#### Train: [  3/100] Step 690/3950 MSE 0.0006+-0.00000\n02/29 08:54:22 PM | #### Train: [  3/100] Step 720/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 720/3950 MSE 0.0005+-0.00000\n02/29 08:54:23 PM | #### Train: [  3/100] Step 750/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 750/3950 MSE 0.0005+-0.00000\n02/29 08:54:23 PM | #### Train: [  3/100] Step 780/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 780/3950 MSE 0.0005+-0.00000\n02/29 08:54:23 PM | #### Train: [  3/100] Step 810/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 810/3950 MSE 0.0005+-0.00000\n02/29 08:54:23 PM | #### Train: [  3/100] Step 840/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 840/3950 MSE 0.0005+-0.00000\n02/29 08:54:23 PM | #### Train: [  3/100] Step 870/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 870/3950 MSE 0.0005+-0.00000\n02/29 08:54:23 PM | #### Train: [  3/100] Step 900/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 900/3950 MSE 0.0005+-0.00000\n02/29 08:54:23 PM | #### Train: [  3/100] Step 930/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 930/3950 MSE 0.0005+-0.00000\n02/29 08:54:23 PM | #### Train: [  3/100] Step 960/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 960/3950 MSE 0.0005+-0.00000\n02/29 08:54:23 PM | #### Train: [  3/100] Step 990/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 990/3950 MSE 0.0005+-0.00000\n02/29 08:54:23 PM | #### Train: [  3/100] Step 1020/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 1020/3950 MSE 0.0005+-0.00000\n02/29 08:54:23 PM | #### Train: [  3/100] Step 1050/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 1050/3950 MSE 0.0005+-0.00000\n02/29 08:54:23 PM | #### Train: [  3/100] Step 1080/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 1080/3950 MSE 0.0005+-0.00000\n02/29 08:54:23 PM | #### Train: [  3/100] Step 1110/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 1110/3950 MSE 0.0005+-0.00000\n02/29 08:54:24 PM | #### Train: [  3/100] Step 1140/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 1140/3950 MSE 0.0005+-0.00000\n02/29 08:54:24 PM | #### Train: [  3/100] Step 1170/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 1170/3950 MSE 0.0005+-0.00000\n02/29 08:54:24 PM | #### Train: [  3/100] Step 1200/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 1200/3950 MSE 0.0005+-0.00000\n02/29 08:54:24 PM | #### Train: [  3/100] Step 1230/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 1230/3950 MSE 0.0005+-0.00000\n02/29 08:54:24 PM | #### Train: [  3/100] Step 1260/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 1260/3950 MSE 0.0005+-0.00000\n02/29 08:54:24 PM | #### Train: [  3/100] Step 1290/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 1290/3950 MSE 0.0005+-0.00000\n02/29 08:54:24 PM | #### Train: [  3/100] Step 1320/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 1320/3950 MSE 0.0005+-0.00000\n02/29 08:54:24 PM | #### Train: [  3/100] Step 1350/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 1350/3950 MSE 0.0005+-0.00000\n02/29 08:54:24 PM | #### Train: [  3/100] Step 1380/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 1380/3950 MSE 0.0005+-0.00000\n02/29 08:54:24 PM | #### Train: [  3/100] Step 1410/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 1410/3950 MSE 0.0005+-0.00000\n02/29 08:54:24 PM | #### Train: [  3/100] Step 1440/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 1440/3950 MSE 0.0005+-0.00000\n02/29 08:54:24 PM | #### Train: [  3/100] Step 1470/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 1470/3950 MSE 0.0005+-0.00000\n02/29 08:54:25 PM | #### Train: [  3/100] Step 1500/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 1500/3950 MSE 0.0005+-0.00000\n02/29 08:54:25 PM | #### Train: [  3/100] Step 1530/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 1530/3950 MSE 0.0005+-0.00000\n02/29 08:54:25 PM | #### Train: [  3/100] Step 1560/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 1560/3950 MSE 0.0005+-0.00000\n02/29 08:54:25 PM | #### Train: [  3/100] Step 1590/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 1590/3950 MSE 0.0005+-0.00000\n02/29 08:54:25 PM | #### Train: [  3/100] Step 1620/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 1620/3950 MSE 0.0005+-0.00000\n02/29 08:54:25 PM | #### Train: [  3/100] Step 1650/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 1650/3950 MSE 0.0005+-0.00000\n02/29 08:54:25 PM | #### Train: [  3/100] Step 1680/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 1680/3950 MSE 0.0005+-0.00000\n02/29 08:54:25 PM | #### Train: [  3/100] Step 1710/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 1710/3950 MSE 0.0005+-0.00000\n02/29 08:54:25 PM | #### Train: [  3/100] Step 1740/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 1740/3950 MSE 0.0005+-0.00000\n02/29 08:54:25 PM | #### Train: [  3/100] Step 1770/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 1770/3950 MSE 0.0005+-0.00000\n02/29 08:54:25 PM | #### Train: [  3/100] Step 1800/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 1800/3950 MSE 0.0005+-0.00000\n02/29 08:54:25 PM | #### Train: [  3/100] Step 1830/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 1830/3950 MSE 0.0005+-0.00000\n02/29 08:54:26 PM | #### Train: [  3/100] Step 1860/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 1860/3950 MSE 0.0005+-0.00000\n02/29 08:54:26 PM | #### Train: [  3/100] Step 1890/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 1890/3950 MSE 0.0005+-0.00000\n02/29 08:54:26 PM | #### Train: [  3/100] Step 1920/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 1920/3950 MSE 0.0005+-0.00000\n02/29 08:54:26 PM | #### Train: [  3/100] Step 1950/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 1950/3950 MSE 0.0005+-0.00000\n02/29 08:54:26 PM | #### Train: [  3/100] Step 1980/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 1980/3950 MSE 0.0005+-0.00000\n02/29 08:54:26 PM | #### Train: [  3/100] Step 2010/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 2010/3950 MSE 0.0005+-0.00000\n02/29 08:54:26 PM | #### Train: [  3/100] Step 2040/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 2040/3950 MSE 0.0005+-0.00000\n02/29 08:54:26 PM | #### Train: [  3/100] Step 2070/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 2070/3950 MSE 0.0005+-0.00000\n02/29 08:54:26 PM | #### Train: [  3/100] Step 2100/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 2100/3950 MSE 0.0005+-0.00000\n02/29 08:54:26 PM | #### Train: [  3/100] Step 2130/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 2130/3950 MSE 0.0004+-0.00000\n02/29 08:54:26 PM | #### Train: [  3/100] Step 2160/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 2160/3950 MSE 0.0004+-0.00000\n02/29 08:54:26 PM | #### Train: [  3/100] Step 2190/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 2190/3950 MSE 0.0005+-0.00000\n02/29 08:54:27 PM | #### Train: [  3/100] Step 2220/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 2220/3950 MSE 0.0004+-0.00000\n02/29 08:54:27 PM | #### Train: [  3/100] Step 2250/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 2250/3950 MSE 0.0004+-0.00000\n02/29 08:54:27 PM | #### Train: [  3/100] Step 2280/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 2280/3950 MSE 0.0004+-0.00000\n02/29 08:54:27 PM | #### Train: [  3/100] Step 2310/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 2310/3950 MSE 0.0004+-0.00000\n02/29 08:54:27 PM | #### Train: [  3/100] Step 2340/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 2340/3950 MSE 0.0004+-0.00000\n02/29 08:54:27 PM | #### Train: [  3/100] Step 2370/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 2370/3950 MSE 0.0004+-0.00000\n02/29 08:54:27 PM | #### Train: [  3/100] Step 2400/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 2400/3950 MSE 0.0004+-0.00000\n02/29 08:54:27 PM | #### Train: [  3/100] Step 2430/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 2430/3950 MSE 0.0004+-0.00000\n02/29 08:54:27 PM | #### Train: [  3/100] Step 2460/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 2460/3950 MSE 0.0004+-0.00000\n02/29 08:54:27 PM | #### Train: [  3/100] Step 2490/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 2490/3950 MSE 0.0004+-0.00000\n02/29 08:54:27 PM | #### Train: [  3/100] Step 2520/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 2520/3950 MSE 0.0004+-0.00000\n02/29 08:54:27 PM | #### Train: [  3/100] Step 2550/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 2550/3950 MSE 0.0004+-0.00000\n02/29 08:54:28 PM | #### Train: [  3/100] Step 2580/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 2580/3950 MSE 0.0004+-0.00000\n02/29 08:54:28 PM | #### Train: [  3/100] Step 2610/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 2610/3950 MSE 0.0004+-0.00000\n02/29 08:54:28 PM | #### Train: [  3/100] Step 2640/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 2640/3950 MSE 0.0004+-0.00000\n02/29 08:54:28 PM | #### Train: [  3/100] Step 2670/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 2670/3950 MSE 0.0005+-0.00000\n02/29 08:54:28 PM | #### Train: [  3/100] Step 2700/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 2700/3950 MSE 0.0005+-0.00000\n02/29 08:54:28 PM | #### Train: [  3/100] Step 2730/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 2730/3950 MSE 0.0005+-0.00000\n02/29 08:54:28 PM | #### Train: [  3/100] Step 2760/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 2760/3950 MSE 0.0005+-0.00000\n02/29 08:54:28 PM | #### Train: [  3/100] Step 2790/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 2790/3950 MSE 0.0005+-0.00000\n02/29 08:54:28 PM | #### Train: [  3/100] Step 2820/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 2820/3950 MSE 0.0005+-0.00000\n02/29 08:54:28 PM | #### Train: [  3/100] Step 2850/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 2850/3950 MSE 0.0005+-0.00000\n02/29 08:54:28 PM | #### Train: [  3/100] Step 2880/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 2880/3950 MSE 0.0005+-0.00000\n02/29 08:54:28 PM | #### Train: [  3/100] Step 2910/3950 MSE 0.0005+-0.00000\nINFO:net:#### Train: [  3/100] Step 2910/3950 MSE 0.0005+-0.00000\n02/29 08:54:29 PM | #### Train: [  3/100] Step 2940/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 2940/3950 MSE 0.0004+-0.00000\n02/29 08:54:29 PM | #### Train: [  3/100] Step 2970/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 2970/3950 MSE 0.0004+-0.00000\n02/29 08:54:29 PM | #### Train: [  3/100] Step 3000/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 3000/3950 MSE 0.0004+-0.00000\n02/29 08:54:29 PM | #### Train: [  3/100] Step 3030/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 3030/3950 MSE 0.0004+-0.00000\n02/29 08:54:29 PM | #### Train: [  3/100] Step 3060/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 3060/3950 MSE 0.0004+-0.00000\n02/29 08:54:29 PM | #### Train: [  3/100] Step 3090/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 3090/3950 MSE 0.0004+-0.00000\n02/29 08:54:29 PM | #### Train: [  3/100] Step 3120/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 3120/3950 MSE 0.0004+-0.00000\n02/29 08:54:29 PM | #### Train: [  3/100] Step 3150/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 3150/3950 MSE 0.0004+-0.00000\n02/29 08:54:29 PM | #### Train: [  3/100] Step 3180/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 3180/3950 MSE 0.0004+-0.00000\n02/29 08:54:29 PM | #### Train: [  3/100] Step 3210/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 3210/3950 MSE 0.0004+-0.00000\n02/29 08:54:29 PM | #### Train: [  3/100] Step 3240/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 3240/3950 MSE 0.0004+-0.00000\n02/29 08:54:29 PM | #### Train: [  3/100] Step 3270/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 3270/3950 MSE 0.0004+-0.00000\n02/29 08:54:29 PM | #### Train: [  3/100] Step 3300/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 3300/3950 MSE 0.0004+-0.00000\n02/29 08:54:30 PM | #### Train: [  3/100] Step 3330/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 3330/3950 MSE 0.0004+-0.00000\n02/29 08:54:30 PM | #### Train: [  3/100] Step 3360/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 3360/3950 MSE 0.0004+-0.00000\n02/29 08:54:30 PM | #### Train: [  3/100] Step 3390/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 3390/3950 MSE 0.0004+-0.00000\n02/29 08:54:30 PM | #### Train: [  3/100] Step 3420/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 3420/3950 MSE 0.0004+-0.00000\n02/29 08:54:30 PM | #### Train: [  3/100] Step 3450/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 3450/3950 MSE 0.0004+-0.00000\n02/29 08:54:30 PM | #### Train: [  3/100] Step 3480/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 3480/3950 MSE 0.0004+-0.00000\n02/29 08:54:30 PM | #### Train: [  3/100] Step 3510/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 3510/3950 MSE 0.0004+-0.00000\n02/29 08:54:30 PM | #### Train: [  3/100] Step 3540/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 3540/3950 MSE 0.0004+-0.00000\n02/29 08:54:30 PM | #### Train: [  3/100] Step 3570/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 3570/3950 MSE 0.0004+-0.00000\n02/29 08:54:30 PM | #### Train: [  3/100] Step 3600/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 3600/3950 MSE 0.0004+-0.00000\n02/29 08:54:30 PM | #### Train: [  3/100] Step 3630/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 3630/3950 MSE 0.0004+-0.00000\n02/29 08:54:30 PM | #### Train: [  3/100] Step 3660/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 3660/3950 MSE 0.0004+-0.00000\n02/29 08:54:31 PM | #### Train: [  3/100] Step 3690/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 3690/3950 MSE 0.0004+-0.00000\n02/29 08:54:31 PM | #### Train: [  3/100] Step 3720/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 3720/3950 MSE 0.0004+-0.00000\n02/29 08:54:31 PM | #### Train: [  3/100] Step 3750/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 3750/3950 MSE 0.0004+-0.00000\n02/29 08:54:31 PM | #### Train: [  3/100] Step 3780/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 3780/3950 MSE 0.0004+-0.00000\n02/29 08:54:31 PM | #### Train: [  3/100] Step 3810/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 3810/3950 MSE 0.0004+-0.00000\n02/29 08:54:31 PM | #### Train: [  3/100] Step 3840/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 3840/3950 MSE 0.0004+-0.00000\n02/29 08:54:31 PM | #### Train: [  3/100] Step 3870/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 3870/3950 MSE 0.0004+-0.00000\n02/29 08:54:31 PM | #### Train: [  3/100] Step 3900/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 3900/3950 MSE 0.0004+-0.00000\n02/29 08:54:31 PM | #### Train: [  3/100] Step 3930/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 3930/3950 MSE 0.0004+-0.00000\n02/29 08:54:31 PM | #### Train: [  3/100] Step 3950/3950 MSE 0.0004+-0.00000\nINFO:net:#### Train: [  3/100] Step 3950/3950 MSE 0.0004+-0.00000\n02/29 08:54:31 PM | _train_step_Train: [  3/100] Final MSE 0.0004+-0.00000 Time 10.86\nINFO:net:_train_step_Train: [  3/100] Final MSE 0.0004+-0.00000 Time 10.86\n02/29 08:54:32 PM | #### Test: [  3/100] Step 030/987 MSE 0.0087+-0.01259\nINFO:net:#### Test: [  3/100] Step 030/987 MSE 0.0087+-0.01259\n02/29 08:54:32 PM | #### Test: [  3/100] Step 060/987 MSE 0.0087+-0.01249\nINFO:net:#### Test: [  3/100] Step 060/987 MSE 0.0087+-0.01249\n02/29 08:54:33 PM | #### Test: [  3/100] Step 090/987 MSE 0.0087+-0.01248\nINFO:net:#### Test: [  3/100] Step 090/987 MSE 0.0087+-0.01248\n02/29 08:54:33 PM | #### Test: [  3/100] Step 120/987 MSE 0.0087+-0.01250\nINFO:net:#### Test: [  3/100] Step 120/987 MSE 0.0087+-0.01250\n02/29 08:54:33 PM | #### Test: [  3/100] Step 150/987 MSE 0.0088+-0.01253\nINFO:net:#### Test: [  3/100] Step 150/987 MSE 0.0088+-0.01253\n02/29 08:54:34 PM | #### Test: [  3/100] Step 180/987 MSE 0.0088+-0.01250\nINFO:net:#### Test: [  3/100] Step 180/987 MSE 0.0088+-0.01250\n02/29 08:54:34 PM | #### Test: [  3/100] Step 210/987 MSE 0.0088+-0.01250\nINFO:net:#### Test: [  3/100] Step 210/987 MSE 0.0088+-0.01250\n02/29 08:54:35 PM | #### Test: [  3/100] Step 240/987 MSE 0.0088+-0.01250\nINFO:net:#### Test: [  3/100] Step 240/987 MSE 0.0088+-0.01250\n02/29 08:54:35 PM | #### Test: [  3/100] Step 270/987 MSE 0.0089+-0.01252\nINFO:net:#### Test: [  3/100] Step 270/987 MSE 0.0089+-0.01252\n02/29 08:54:36 PM | #### Test: [  3/100] Step 300/987 MSE 0.0089+-0.01256\nINFO:net:#### Test: [  3/100] Step 300/987 MSE 0.0089+-0.01256\n02/29 08:54:36 PM | #### Test: [  3/100] Step 330/987 MSE 0.0089+-0.01255\nINFO:net:#### Test: [  3/100] Step 330/987 MSE 0.0089+-0.01255\n02/29 08:54:37 PM | #### Test: [  3/100] Step 360/987 MSE 0.0090+-0.01257\nINFO:net:#### Test: [  3/100] Step 360/987 MSE 0.0090+-0.01257\n02/29 08:54:37 PM | #### Test: [  3/100] Step 390/987 MSE 0.0090+-0.01257\nINFO:net:#### Test: [  3/100] Step 390/987 MSE 0.0090+-0.01257\n02/29 08:54:37 PM | #### Test: [  3/100] Step 420/987 MSE 0.0090+-0.01257\nINFO:net:#### Test: [  3/100] Step 420/987 MSE 0.0090+-0.01257\n02/29 08:54:38 PM | #### Test: [  3/100] Step 450/987 MSE 0.0090+-0.01258\nINFO:net:#### Test: [  3/100] Step 450/987 MSE 0.0090+-0.01258\n02/29 08:54:38 PM | #### Test: [  3/100] Step 480/987 MSE 0.0090+-0.01258\nINFO:net:#### Test: [  3/100] Step 480/987 MSE 0.0090+-0.01258\n02/29 08:54:39 PM | #### Test: [  3/100] Step 510/987 MSE 0.0090+-0.01260\nINFO:net:#### Test: [  3/100] Step 510/987 MSE 0.0090+-0.01260\n02/29 08:54:39 PM | #### Test: [  3/100] Step 540/987 MSE 0.0090+-0.01260\nINFO:net:#### Test: [  3/100] Step 540/987 MSE 0.0090+-0.01260\n02/29 08:54:40 PM | #### Test: [  3/100] Step 570/987 MSE 0.0090+-0.01261\nINFO:net:#### Test: [  3/100] Step 570/987 MSE 0.0090+-0.01261\n02/29 08:54:40 PM | #### Test: [  3/100] Step 600/987 MSE 0.0090+-0.01262\nINFO:net:#### Test: [  3/100] Step 600/987 MSE 0.0090+-0.01262\n02/29 08:54:41 PM | #### Test: [  3/100] Step 630/987 MSE 0.0090+-0.01261\nINFO:net:#### Test: [  3/100] Step 630/987 MSE 0.0090+-0.01261\n02/29 08:54:41 PM | #### Test: [  3/100] Step 660/987 MSE 0.0090+-0.01261\nINFO:net:#### Test: [  3/100] Step 660/987 MSE 0.0090+-0.01261\n02/29 08:54:41 PM | #### Test: [  3/100] Step 690/987 MSE 0.0090+-0.01262\nINFO:net:#### Test: [  3/100] Step 690/987 MSE 0.0090+-0.01262\n"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-836267397c03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/aihack2020/prediction/api.py\u001b[0m in \u001b[0;36mget_model\u001b[0;34m(train_loader, test_loader)\u001b[0m\n\u001b[1;32m    107\u001b[0m   \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m   \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/aihack2020/prediction/train.py\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(self, train_loader, test_loader)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/aihack2020/prediction/train.py\u001b[0m in \u001b[0;36m_validate\u001b[0;34m(self, loader, epoch)\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                     \u001b[0mstd\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m                 \u001b[0mstd\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = get_model(train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}